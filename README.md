# Automated-evaluation-of-descriptive-answers

The project aimed to develop an automated system for evaluating and analyzing descriptive answers to open-ended questions using Natural Language Processing (NLP) techniques and Machine Learning (ML) models. The objectives were to preprocess natural language data, perform plagiarism detection, grammar checking, and measure the semantic similarity between student answers and reference solutions. The project involved implementing techniques such as tokenization, lemmatization, word embeddings (TF-IDF, Word2Vec, BERT, ELMo), similarity measures (Cosine Similarity, Word Mover's Distance), and machine learning models (Multinomial Naive Bayes, Linear SVC, XLNet). The deliverables included a self-generated dataset of original answers, student answers, and grades, as well as the implemented system capable of preprocessing data, detecting plagiarism, measuring similarity, predicting results, and evaluating descriptive answers using both NLP and ML methods.
